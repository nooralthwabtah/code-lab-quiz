{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nooralthwabtah/code-lab-quiz/blob/main/Copy_of_Wetaan_Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Imports**"
      ],
      "metadata": {
        "id": "Gv0-M_SOx2DH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3V9l23ivqQ1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data**"
      ],
      "metadata": {
        "id": "XFZlDg06x3Zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define transforms (convert images to tensors and normalize)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # normalize MNIST images\n",
        "])\n",
        "\n",
        "# 2. Load datasets\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "wBQhNv4gxlCu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48a6ffb3-31df-4552-cf8c-b78076c7a4b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 12.4MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 341kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 2.70MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.57MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sample Image**"
      ],
      "metadata": {
        "id": "RnFi4nOMx_kC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Visualize one sample image\n",
        "for images, labels in trainloader:\n",
        "    break\n",
        "\n",
        "plt.imshow(images[0].squeeze(), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title(f\"Label: {labels[0].item()}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z16WJOAVxqNx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "a4c5dd11-2f8a-4c0c-a211-2913e3b69c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAADqRJREFUeJzt3FmIV/X7wPHnm/YrFwgrjRaoJHMUhhbNFlosoynqYiYsuiiRUMG6KKVC27SbFiiSqKwoLdGbMkeCQi9KKUO0sCLTIQuNitRRKw1tc87/4gcPP/9jNeeks/l6XdXhPJ7P6AxvjuM8taIoigCAiDiqqw8AQPchCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCvRKW7ZsiVqtFk8++eQh+zVXrlwZtVotVq5cech+TehuRIFu49VXX41arRYff/xxVx/lsGhubo6GhoY45ZRT4phjjonTTjstxo8fH+vXr+/qo0Hq29UHgCPF559/HoMGDYq77rorTjzxxNi6dWvMmzcvxowZE6tXr45zzjmnq48IogCd5eGHH253bdKkSXHaaafF3Llz44UXXuiCU8GB/PURPcrvv/8eDz/8cIwaNSqOO+64GDBgQFx22WWxYsWKv5x5+umn4/TTT49+/frFFVdccdC/rmlpaYnx48fH8ccfH8cee2yMHj063nrrrX88z969e6OlpSV27NhR6eMZMmRI9O/fP3766adK83CoiQI9yu7du+Pll1+OsWPHxhNPPBGzZ8+O1tbWaGhoiE8//bTd/QsWLIhnnnkm7rzzzpg5c2asX78+rrrqqti2bVve88UXX8RFF10UGzdujBkzZsRTTz0VAwYMiMbGxmhubv7b86xduzZGjBgRzz77bIc/hp9++ilaW1vj888/j0mTJsXu3btj3LhxHZ6Hw6qAbmL+/PlFRBQfffTRX97z559/Fr/99tsB13788cfipJNOKm6//fa8tnnz5iIiin79+hXfffddXl+zZk0REcW0adPy2rhx44r6+vri119/zWttbW3FJZdcUgwbNiyvrVixooiIYsWKFe2uzZo1q8Mf5/Dhw4uIKCKiGDhwYPHggw8W+/fv7/A8HE7eFOhR+vTpE//5z38iIqKtrS127doVf/75Z4wePTrWrVvX7v7GxsY49dRT8//HjBkTF154YbzzzjsREbFr165477334uabb449e/bEjh07YseOHbFz585oaGiITZs2xffff/+X5xk7dmwURRGzZ8/u8Mcwf/78WLZsWTz//PMxYsSI2LdvX+zfv7/D83A4+UYzPc5rr70WTz31VLS0tMQff/yR188888x29w4bNqzdtbPPPjtef/31iIj46quvoiiKeOihh+Khhx466PO2b99+QFj+rYsvvjj/+5ZbbokRI0ZERBzSn6mAqkSBHmXhwoUxceLEaGxsjHvvvTeGDBkSffr0icceeyy+/vrr0r9eW1tbRETcc8890dDQcNB7zjrrrH915r8zaNCguOqqq2LRokWiQLcgCvQoixcvjqFDh8aSJUuiVqvl9VmzZh30/k2bNrW79uWXX8YZZ5wRERFDhw6NiIijjz46rr766kN/4A7Yt29f/Pzzz13ybPj/fE+BHqVPnz4REVEURV5bs2ZNrF69+qD3L1269IDvCaxduzbWrFkT1113XUT895+Ejh07Nl588cX44Ycf2s23trb+7XnK/JPU7du3t7u2ZcuWePfdd2P06NH/OA+dwZsC3c68efNi2bJl7a7fddddccMNN8SSJUuiqakprr/++ti8eXO88MILMXLkyPjll1/azZx11llx6aWXxtSpU+O3336LOXPmxAknnBD33Xdf3vPcc8/FpZdeGvX19TF58uQYOnRobNu2LVavXh3fffddfPbZZ3951rVr18aVV14Zs2bN+sdvNtfX18e4cePi3HPPjUGDBsWmTZvilVdeiT/++CMef/zxjv8GwWEkCnQ7c+fOPej1iRMnxsSJE2Pr1q3x4osvxvLly2PkyJGxcOHCeOONNw66qG7ChAlx1FFHxZw5c2L79u0xZsyYePbZZ+Pkk0/Oe0aOHBkff/xxPPLII/Hqq6/Gzp07Y8iQIXHeeecd9KeQq5o6dWq8/fbbsWzZstizZ08MGTIkrrnmmrj//vujvr7+kD0H/o1a8b/v4QAc0XxPAYAkCgAkUQAgiQIASRQASKIAQOrwzyn870oBAHqejvwEgjcFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgCkvl19APgnTU1NpWcaGhoOw0nau/zyy0vPbNiwodKzpk6dWnqmtbW10rM4cnlTACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAqhVFUXToxlrtcJ+FXq7KYruIiAULFpSe6d+/f+mZDn4pHKDK10WV50REfPvtt6Vnpk+fXnqmubm59Aw9Q0c+97wpAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAg9e3qA3DkaGhoqDRXZbndunXrSs8sWbKk9MyHH35YeqaxsbH0TETE3XffXXpm8eLFpWfGjx9fesYSvd7DmwIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAFKtKIqiQzfWaof7LPRyVRa6RUQ8+eSTpWf69u19ux73799feqaDX94H+OSTT0rPXHDBBaVn6Hwd+XzwpgBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKAKTet0qSbmvOnDmV5r755ptDe5Ae6tFHHy09c//99x+Gk9CbeVMAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAECyEI9ur7m5uauPcEjV1dVVmhs5cmTpmaIoKj2LI5c3BQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJAvx4F+YNm1a6ZkZM2ZUetbgwYNLz1RZiLd06dLSM/Qe3hQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBqRQc3ZtVqtcN9Fnq5KgvdIiKampoO8UkO3XOuueaa0jNVltRFVPsa3LBhQ+mZ+vr60jP0DB353POmAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoApL5dfQB6pssvv7z0zMqVKys9q8pW0SobRTvrOVXt3Lmz9MyHH35Yeqaurq70TEtLS+kZuidvCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASLWig1vAOnPxF93flClTSs/MnTu30rN620K8Ks/pzGft27ev9MyECRNKzzQ3N5ee4d/pyOeDNwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACQL8aikqamp9MyNN95Y6VlVlrqtWrWq0rPKeumll0rP1NXVVXrWzp07S8/MnDmz9Mzdd99deqbKn9GVV15ZeiYi4v333680h4V4AJQkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIAyUI84AD79+8vPVNlId4dd9xReiai2hJC/stCPABKEQUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgNS3qw8AdC+dtfyytbW1U55DOd4UAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAZEsq9BCDBw8uPTNz5szSM0VRlJ7ZsGFD6Znm5ubSMxx+3hQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJCO6IV4U6ZMKT0zefLk0jMXXHBB6Rl6r6ampkpzt956a+mZxsbG0jN79+4tPXPTTTeVnqF78qYAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYB0RC/Eq6Kurq5TZlpaWkrP8O9U+XN64IEHSs9UWVIXEdG/f//SM0VRlJ6ZMGFC6Rmfr72HNwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACQL8UoaOHBg6Zk333yz9MzYsWNLz0REtLa2VprrDNdee22luSoL5AYPHtwpz6nVaqVnqv4ZrVq1qvTMbbfdVnpmx44dpWfoPbwpAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgWYhXUltbW+mZ4cOHl55Zu3Zt6ZmI7r3M7Pzzz680VxRF6Zkqi+qqPKfK7/f06dNLz0RELFq0qNIclOFNAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASLWig6shq2yd7I0eeOCB0jMzZswoPTNw4MDSMxHVtrh21kbRqp9DGzduLD2zfPny0jMtLS2lZ1566aXSM9BVOvJ1600BgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgDJQrxOUFdXV3pm1KhRlZ5VZfneqlWrSs9UWR73wQcflJ6p+qy9e/dWehb0ZhbiAVCKKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJAvxAI4QFuIBUIooAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgCkvh29sSiKw3kOALoBbwoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoApP8Dp2G30+T9AdgAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Define CNN model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # First conv layer: input channels=1 (grayscale), output channels=32, kernel 3x3\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        # Second conv layer: input 32, output 64\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        # Max pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))   # (batch, 32, 28, 28)\n",
        "        x = self.pool(x)            # (batch, 32, 14, 14)\n",
        "        x = F.relu(self.conv2(x))   # (batch, 64, 14, 14)\n",
        "        x = self.pool(x)            # (batch, 64, 7, 7)\n",
        "        x = x.view(-1, 64 * 7 * 7) # flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "25TvgpX9x6f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Initialize model, loss, optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "6zJXzn-iKIr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Training loop\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in trainloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(trainloader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCGJNMY1KQPy",
        "outputId": "059fc539-e6d4-477a-ee85-2a436866e201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.1319\n",
            "Epoch 2/5, Loss: 0.0427\n",
            "Epoch 3/5, Loss: 0.0282\n",
            "Epoch 4/5, Loss: 0.0202\n",
            "Epoch 5/5, Loss: 0.0166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to save the model\n",
        "torch.save(model.state_dict(), \"mnist_cnn.pth\")\n",
        "print(\"Model saved to mnist_cnn.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-5dmlsnPBYo",
        "outputId": "ef167833-a161-47bd-990c-40246877ca00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to mnist_cnn.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to download the model in my computer\n",
        "from google.colab import files\n",
        "files.download(\"mnist_cnn.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "FxSKn4ufPawm",
        "outputId": "f77dcf69-e140-46f1-cdbb-c57dd59d539f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_620c181f-a807-4f7a-ade4-2396a7e2f940\", \"mnist_cnn.pth\", 1689752)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Evaluation on test data\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRCWk_KCKb60",
        "outputId": "b909fa0a-e802-4b3c-e3da-59da8c5eff35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 99.15%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bonus Task:**\n",
        "Link the model to an interactive streamlit app :)"
      ],
      "metadata": {
        "id": "1Iydl9hZxpR9"
      }
    }
  ]
}